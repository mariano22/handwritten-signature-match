{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d1f410f-ecee-4d31-8c90-04be99419adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import PIL\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "from src.datasets import sigcomp2009, mnist, cedar\n",
    "from src.pair_dataset import *\n",
    "from src.visualization import *\n",
    "from src.tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8586924-b080-4f4a-87f9-5ccba19f6408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c71edfa-874a-418b-ac7b-655bac009cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3372ff2c-6a53-424c-8af4-f102fd124479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b489b-0ceb-48bb-8c4c-b99f4c19ee16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dad72a-e10c-4db6-81b8-c2d7a9c70d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5ff70-70cd-47ba-85a7-d276c3e6fdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ed1a896-0e62-4af4-9db8-e2b68ae6a14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.119607843137255,\n",
       " 2.8202764976958523,\n",
       " 1.0769230769230769,\n",
       " 1.3888888888888888,\n",
       " 1.253787878787879,\n",
       " 1.3170731707317074,\n",
       " 1.8056426332288402,\n",
       " 2.3043478260869565,\n",
       " 1.2177121771217712,\n",
       " 1.9811320754716981,\n",
       " 1.3076923076923077,\n",
       " 1.3866666666666667,\n",
       " 1.0634573304157549,\n",
       " 1.5818181818181818,\n",
       " 1.0,\n",
       " 1.4264705882352942,\n",
       " 1.5816618911174785,\n",
       " 1.7119113573407203,\n",
       " 1.2848232848232848,\n",
       " 1.553133514986376,\n",
       " 0.8382352941176471,\n",
       " 1.96,\n",
       " 1.1464019851116625,\n",
       " 1.6612903225806452,\n",
       " 1.7626112759643917,\n",
       " 2.5714285714285716,\n",
       " 1.2133333333333334,\n",
       " 1.5777777777777777,\n",
       " 1.26,\n",
       " 1.2601880877742946,\n",
       " 1.5623268698060941,\n",
       " 1.9607843137254901,\n",
       " 1.358974358974359,\n",
       " 2.3823529411764706,\n",
       " 1.5521235521235521,\n",
       " 1.6085790884718498,\n",
       " 1.3666666666666667,\n",
       " 1.130952380952381,\n",
       " 1.3424657534246576,\n",
       " 1.6786703601108033,\n",
       " 2.101083032490975,\n",
       " 1.0449438202247192,\n",
       " 1.416867469879518,\n",
       " 1.3478260869565217,\n",
       " 1.1362126245847175,\n",
       " 1.2619047619047619,\n",
       " 1.1971496437054632,\n",
       " 1.5869017632241813,\n",
       " 1.5498721227621484,\n",
       " 2.2261484098939928,\n",
       " 1.3636363636363635,\n",
       " 2.3176895306859207,\n",
       " 1.5498721227621484,\n",
       " 1.1241217798594847,\n",
       " 1.2720848056537102,\n",
       " 1.175,\n",
       " 1.4602409638554217,\n",
       " 2.0179372197309418,\n",
       " 1.3150684931506849,\n",
       " 2.1544401544401546,\n",
       " 1.5483870967741935,\n",
       " 1.3174603174603174,\n",
       " 1.5955678670360112,\n",
       " 1.3205128205128205,\n",
       " 1.8602620087336244,\n",
       " 1.7258064516129032,\n",
       " 1.6349206349206349,\n",
       " 1.5379061371841156,\n",
       " 1.8737541528239203,\n",
       " 1.5989445910290236,\n",
       " 1.3505535055350553,\n",
       " 1.328719723183391,\n",
       " 1.9444444444444444,\n",
       " 1.1816192560175054,\n",
       " 1.4848484848484849,\n",
       " 2.1660649819494586,\n",
       " 1.8915254237288135,\n",
       " 1.9298245614035088,\n",
       " 1.0304709141274238,\n",
       " 1.6363636363636365,\n",
       " 0.9651474530831099,\n",
       " 1.5070422535211268,\n",
       " 1.8338870431893688,\n",
       " 1.2958963282937366,\n",
       " 1.225,\n",
       " 1.4827586206896552,\n",
       " 1.2352941176470589,\n",
       " 1.2972972972972974,\n",
       " 1.2317073170731707,\n",
       " 1.9423076923076923,\n",
       " 1.641025641025641,\n",
       " 1.3846153846153846,\n",
       " 1.0,\n",
       " 1.2995495495495495,\n",
       " 2.218867924528302,\n",
       " 1.2321428571428572,\n",
       " 2.5394190871369293,\n",
       " 1.6995515695067265,\n",
       " 1.5393586005830904,\n",
       " 1.2125,\n",
       " 2.4545454545454546,\n",
       " 2.14,\n",
       " 1.8092307692307692,\n",
       " 1.2692307692307692,\n",
       " 1.4603174603174602,\n",
       " 1.3992094861660078,\n",
       " 1.2462908011869436,\n",
       " 2.567685589519651,\n",
       " 1.4285714285714286,\n",
       " 1.6363636363636365,\n",
       " 1.3783783783783783,\n",
       " 1.553191489361702,\n",
       " 2.2934362934362933,\n",
       " 1.749216300940439,\n",
       " 1.5918367346938775,\n",
       " 1.2765957446808511,\n",
       " 1.8276923076923077,\n",
       " 1.2027334851936218,\n",
       " 1.482185273159145,\n",
       " 1.3289902280130292,\n",
       " 1.4647887323943662,\n",
       " 2.1463414634146343,\n",
       " 1.8737541528239203,\n",
       " 1.5959079283887467,\n",
       " 1.3055555555555556,\n",
       " 2.179372197309417,\n",
       " 1.1875,\n",
       " 1.250965250965251,\n",
       " 2.3247232472324724,\n",
       " 1.3752808988764045,\n",
       " 1.054054054054054,\n",
       " 1.4048140043763677,\n",
       " 1.8051575931232091,\n",
       " 1.1085450346420322,\n",
       " 1.974921630094044,\n",
       " 1.651948051948052,\n",
       " 1.381132075471698,\n",
       " 1.83011583011583,\n",
       " 1.65,\n",
       " 2.0144404332129966,\n",
       " 1.5457063711911356,\n",
       " 1.3801916932907348,\n",
       " 2.230769230769231,\n",
       " 1.206896551724138,\n",
       " 1.791549295774648,\n",
       " 1.2297297297297298,\n",
       " 2.1476014760147604,\n",
       " 1.2651757188498403,\n",
       " 1.3137254901960784,\n",
       " 2.690582959641256,\n",
       " 1.3394077448747153,\n",
       " 1.530612244897959,\n",
       " 1.146341463414634,\n",
       " 1.2598752598752598,\n",
       " 1.6153846153846154,\n",
       " 2.6367713004484306,\n",
       " 1.6188340807174888,\n",
       " 1.0790190735694822,\n",
       " 1.3568904593639577,\n",
       " 1.974921630094044,\n",
       " 1.542319749216301,\n",
       " 1.1511627906976745,\n",
       " 1.8977635782747604,\n",
       " 2.7319148936170214,\n",
       " 2.169741697416974,\n",
       " 1.2,\n",
       " 1.4801587301587302,\n",
       " 2.5375494071146245,\n",
       " 1.1016949152542372,\n",
       " 1.3485477178423237,\n",
       " 1.0228070175438597,\n",
       " 1.0866425992779782,\n",
       " 1.4927536231884058,\n",
       " 1.279317697228145,\n",
       " 1.7353846153846153,\n",
       " 2.8520179372197307,\n",
       " 2.5892116182572615,\n",
       " 1.610223642172524,\n",
       " 1.075,\n",
       " 1.5197889182058046,\n",
       " 2.2867924528301886,\n",
       " 1.9277978339350181,\n",
       " 1.4264150943396225,\n",
       " 0.9815303430079155,\n",
       " 1.6454293628808865,\n",
       " 1.8518518518518519,\n",
       " 1.3835920177383592,\n",
       " 1.836734693877551,\n",
       " 1.5197889182058046,\n",
       " 1.290566037735849,\n",
       " 1.3037974683544304,\n",
       " 1.6952908587257618,\n",
       " 1.823321554770318,\n",
       " 1.4332552693208431,\n",
       " 1.7804154302670623,\n",
       " 1.2098765432098766,\n",
       " 1.4155844155844155,\n",
       " 1.6866359447004609,\n",
       " 1.2153518123667377,\n",
       " 1.170731707317073,\n",
       " 2.11336032388664,\n",
       " 1.456179775280899,\n",
       " 1.8851963746223566,\n",
       " 1.6744186046511629,\n",
       " 1.2090680100755669,\n",
       " 1.8594249201277955,\n",
       " 1.6786703601108033,\n",
       " 1.154394299287411,\n",
       " 1.4230769230769231,\n",
       " 1.2,\n",
       " 1.1272015655577299,\n",
       " 2.286995515695067,\n",
       " 1.0749185667752443,\n",
       " 1.2692307692307692,\n",
       " 1.6451612903225807,\n",
       " 1.7047970479704797,\n",
       " 1.7540983606557377,\n",
       " 1.4229828850855746,\n",
       " 1.4805194805194806,\n",
       " 1.911864406779661,\n",
       " 1.4202898550724639,\n",
       " 1.3436293436293436,\n",
       " 1.716923076923077,\n",
       " 1.7307692307692308,\n",
       " 2.169741697416974,\n",
       " 1.312910284463895,\n",
       " 1.507462686567164,\n",
       " 1.7879656160458453,\n",
       " 1.0421836228287842,\n",
       " 1.4612546125461254,\n",
       " 1.424802110817942,\n",
       " 2.101083032490975,\n",
       " 1.0675675675675675,\n",
       " 1.561128526645768,\n",
       " 1.6848137535816619,\n",
       " 2.1201413427561837,\n",
       " 2.623481781376518,\n",
       " 1.4746987951807229,\n",
       " 1.5909090909090908,\n",
       " 3.304812834224599,\n",
       " 1.2332155477031803,\n",
       " 1.0897435897435896,\n",
       " 1.490990990990991,\n",
       " 1.2395833333333333,\n",
       " 0.9230769230769231,\n",
       " 1.1762820512820513,\n",
       " 2.782978723404255,\n",
       " 0.8975069252077562,\n",
       " 1.6833333333333333,\n",
       " 2.4787644787644787,\n",
       " 1.7879656160458453,\n",
       " 2.055363321799308,\n",
       " 1.356164383561644,\n",
       " 1.6175548589341693,\n",
       " 1.0595238095238095,\n",
       " 0.8,\n",
       " 1.3194444444444444,\n",
       " 2.0625,\n",
       " 1.7408450704225351,\n",
       " 1.4811083123425692,\n",
       " 1.5060728744939271,\n",
       " 1.462686567164179,\n",
       " 1.9795918367346939,\n",
       " 1.6363636363636365,\n",
       " 1.8762214983713354,\n",
       " 1.1384615384615384,\n",
       " 1.5060728744939271,\n",
       " 1.7727272727272727,\n",
       " 1.3936430317848412,\n",
       " 2.2140221402214024,\n",
       " 1.5858310626702998,\n",
       " 1.2779783393501805,\n",
       " 0.9404388714733543,\n",
       " 1.631336405529954,\n",
       " 1.5356200527704484,\n",
       " 2.150943396226415,\n",
       " 2.4292682926829268,\n",
       " 1.2962962962962963,\n",
       " 1.745152354570637,\n",
       " 1.3026315789473684,\n",
       " 1.216400911161731,\n",
       " 1.6325088339222615,\n",
       " 1.5781637717121588,\n",
       " 2.4292682926829268,\n",
       " 2.012539184952978,\n",
       " 1.2352941176470589,\n",
       " 1.4098360655737705,\n",
       " 1.1814671814671815,\n",
       " 2.7437185929648242,\n",
       " 1.2665245202558635,\n",
       " 1.4634146341463414,\n",
       " 1.1428571428571428,\n",
       " 1.2803970223325063,\n",
       " 1.9811320754716981,\n",
       " 2.2422145328719725,\n",
       " 1.3995381062355658,\n",
       " 2.262975778546713,\n",
       " 1.4133949191685913,\n",
       " 1.065217391304348,\n",
       " 1.625,\n",
       " 2.0890688259109313,\n",
       " 1.5605381165919283,\n",
       " 1.1547619047619047,\n",
       " 1.1236749116607774,\n",
       " 1.3349633251833741,\n",
       " 1.7,\n",
       " 1.1931818181818181,\n",
       " 1.639344262295082,\n",
       " 1.541501976284585,\n",
       " 1.5303030303030303,\n",
       " 1.2289156626506024,\n",
       " 2.056537102473498,\n",
       " 1.5038363171355498,\n",
       " 1.5223880597014925,\n",
       " 2.096069868995633,\n",
       " 1.7535816618911175,\n",
       " 1.3754940711462451,\n",
       " 2.1227436823104693,\n",
       " 1.494809688581315,\n",
       " 1.3212996389891696,\n",
       " 1.2833333333333334,\n",
       " 2.5145228215767634,\n",
       " 1.2365339578454333,\n",
       " 1.565217391304348,\n",
       " 1.4246575342465753,\n",
       " 1.8092307692307692,\n",
       " 1.6939313984168864,\n",
       " 2.1152542372881356,\n",
       " 2.2,\n",
       " 1.6246648793565683,\n",
       " 1.8084507042253521,\n",
       " 1.0,\n",
       " 1.0554216867469879,\n",
       " 1.4868804664723032,\n",
       " 1.3417721518987342,\n",
       " 2.013840830449827,\n",
       " 2.7136929460580914,\n",
       " 1.8210862619808306,\n",
       " 1.4383561643835616,\n",
       " 3.077720207253886,\n",
       " 0.7142857142857143,\n",
       " 1.2745098039215685,\n",
       " 1.0549645390070923,\n",
       " 1.2298850574712643,\n",
       " 1.375,\n",
       " 1.6504297994269341,\n",
       " 1.5272727272727273,\n",
       " 1.2692307692307692,\n",
       " 1.3857142857142857,\n",
       " 2.8378378378378377,\n",
       " 1.4357682619647356,\n",
       " 1.691119691119691,\n",
       " 1.294871794871795,\n",
       " 1.6952908587257618,\n",
       " 1.2118811881188118,\n",
       " 1.523076923076923,\n",
       " 1.0795454545454546,\n",
       " 1.4729241877256318,\n",
       " 1.489156626506024,\n",
       " 1.2469135802469136,\n",
       " 1.4788732394366197,\n",
       " 1.7427385892116183,\n",
       " 1.6407506702412868,\n",
       " 1.2084805653710247,\n",
       " 1.2710706150341686,\n",
       " 1.2073170731707317,\n",
       " 2.061224489795918,\n",
       " 1.388646288209607,\n",
       " 2.1544401544401546,\n",
       " 1.749216300940439,\n",
       " 1.146814404432133,\n",
       " 1.380952380952381,\n",
       " 2.1693811074918568,\n",
       " 2.451063829787234,\n",
       " 2.0588235294117645,\n",
       " 1.6147757255936674,\n",
       " 1.8308157099697886,\n",
       " 2.128301886792453,\n",
       " 1.7401812688821752,\n",
       " 1.2619047619047619,\n",
       " 2.13953488372093,\n",
       " 2.4398340248962658,\n",
       " 1.553133514986376,\n",
       " 1.141304347826087,\n",
       " 2.0912052117263844,\n",
       " 1.7270029673590503,\n",
       " 2.3911439114391144,\n",
       " 2.4647302904564317,\n",
       " 1.7457627118644068,\n",
       " 2.0123076923076924,\n",
       " 1.8893617021276596,\n",
       " 1.6551724137931034,\n",
       " 1.9922779922779923,\n",
       " 1.463768115942029,\n",
       " 1.151291512915129,\n",
       " 1.7119113573407203,\n",
       " 1.2777777777777777,\n",
       " 2.0,\n",
       " 1.3752808988764045,\n",
       " 1.2452830188679245,\n",
       " 1.4126984126984128,\n",
       " 1.7485714285714287,\n",
       " 1.3076923076923077,\n",
       " 1.2435897435897436,\n",
       " 1.4411085450346421,\n",
       " 1.4740484429065743,\n",
       " 1.4,\n",
       " 1.1439252336448598,\n",
       " 1.8160237388724036,\n",
       " 1.1948051948051948,\n",
       " 1.826086956521739,\n",
       " 1.2413793103448276,\n",
       " 1.3380281690140845,\n",
       " 1.6185286103542234,\n",
       " 3.125,\n",
       " 1.1168831168831168,\n",
       " 1.6454293628808865,\n",
       " 1.6470588235294117,\n",
       " 1.9444444444444444,\n",
       " 1.4612546125461254,\n",
       " 1.510688836104513,\n",
       " 1.5072463768115942,\n",
       " 1.275,\n",
       " 1.674911660777385,\n",
       " 2.2261484098939928,\n",
       " 3.073170731707317,\n",
       " 1.371824480369515,\n",
       " 1.132936507936508,\n",
       " 2.1544401544401546,\n",
       " 1.2666666666666666,\n",
       " 1.496437054631829,\n",
       " 1.2808988764044944,\n",
       " 1.5186104218362282,\n",
       " 1.378787878787879,\n",
       " 1.1685393258426966,\n",
       " 1.435215946843854,\n",
       " 1.3529411764705883,\n",
       " 1.4590570719602978,\n",
       " 1.3736501079913608,\n",
       " 1.3617977528089888,\n",
       " 1.5380281690140845,\n",
       " 1.032069970845481,\n",
       " 1.4634146341463414,\n",
       " 1.334894613583138,\n",
       " 1.7285318559556786,\n",
       " 1.4077448747152619,\n",
       " 2.1660649819494586,\n",
       " 2.0444444444444443,\n",
       " 1.12984496124031,\n",
       " 1.5517241379310345,\n",
       " 1.7448071216617211,\n",
       " 1.673913043478261,\n",
       " 1.542857142857143,\n",
       " 2.4149377593360994,\n",
       " 1.643076923076923,\n",
       " 1.7746478873239437,\n",
       " 2.12,\n",
       " 2.0676923076923077,\n",
       " 0.8803986710963455,\n",
       " 2.0912052117263844,\n",
       " 1.5087719298245614,\n",
       " 2.169741697416974,\n",
       " 1.2588652482269505,\n",
       " 1.1529411764705881,\n",
       " 1.667621776504298,\n",
       " 1.0736842105263158,\n",
       " 1.6225352112676057,\n",
       " 1.7843137254901962,\n",
       " 2.4787644787644787,\n",
       " 1.6201780415430267,\n",
       " 1.253968253968254,\n",
       " 1.1309904153354633,\n",
       " 1.8703703703703705,\n",
       " 1.4961038961038962,\n",
       " 1.7826086956521738,\n",
       " 1.3116883116883118,\n",
       " 1.3333333333333333,\n",
       " 2.159090909090909,\n",
       " 1.8957654723127035,\n",
       " 2.1476014760147604,\n",
       " 2.0,\n",
       " 2.0332225913621262,\n",
       " 0.9809027777777778,\n",
       " 1.5955678670360112,\n",
       " 1.7211796246648794,\n",
       " 1.3904282115869018,\n",
       " 1.2723492723492724,\n",
       " 1.2173913043478262,\n",
       " 0.9530685920577617,\n",
       " 1.8092307692307692,\n",
       " 1.394736842105263,\n",
       " 1.567282321899736,\n",
       " 1.1762376237623762,\n",
       " 1.3355481727574752,\n",
       " 1.5,\n",
       " 1.0749542961608776,\n",
       " 1.3801916932907348,\n",
       " 1.391304347826087,\n",
       " 1.523076923076923,\n",
       " 1.5197889182058046,\n",
       " 1.2151898734177216,\n",
       " 1.6504297994269341,\n",
       " 2.386100386100386,\n",
       " 1.2609699769053118,\n",
       " 3.0294117647058822,\n",
       " 1.1895833333333334,\n",
       " 1.1666666666666667,\n",
       " 2.4901185770750986,\n",
       " 1.8154981549815499,\n",
       " 1.2987012987012987,\n",
       " 1.5442359249329758,\n",
       " 1.564102564102564,\n",
       " 1.4965357967667436,\n",
       " 1.2848232848232848,\n",
       " 1.506726457399103,\n",
       " 1.4102564102564104,\n",
       " 1.5403422982885087,\n",
       " 1.5955678670360112,\n",
       " 1.1511627906976745,\n",
       " 1.4264705882352942,\n",
       " 1.3246753246753247,\n",
       " 3.0146341463414634,\n",
       " 1.894736842105263,\n",
       " 1.2723492723492724,\n",
       " 1.411764705882353,\n",
       " 1.1341463414634145,\n",
       " 1.5833333333333333,\n",
       " 1.4492753623188406,\n",
       " 1.2601880877742946,\n",
       " 1.4651741293532339,\n",
       " 1.52442996742671,\n",
       " 1.0978260869565217,\n",
       " 2.05111821086262,\n",
       " 1.170731707317073,\n",
       " 1.0,\n",
       " 1.4963325183374083,\n",
       " 1.1174089068825912,\n",
       " 1.144578313253012,\n",
       " 1.6793002915451896,\n",
       " 1.2845070422535212,\n",
       " 1.6967930029154519,\n",
       " 1.6781002638522426,\n",
       " 1.628808864265928,\n",
       " 1.1604938271604939,\n",
       " 1.9505300353356891,\n",
       " 1.4028169014084506,\n",
       " 1.8936170212765957,\n",
       " 2.1056603773584905,\n",
       " 1.4848484848484849,\n",
       " 1.0,\n",
       " 1.719298245614035,\n",
       " 1.197651663405088,\n",
       " 2.296028880866426,\n",
       " 1.8888888888888888,\n",
       " 1.7,\n",
       " 2.3690036900369003,\n",
       " 2.6141078838174274,\n",
       " 2.014760147601476,\n",
       " 1.3351206434316354,\n",
       " 2.775,\n",
       " 1.32378223495702,\n",
       " 1.9552715654952078,\n",
       " 1.8245614035087718,\n",
       " 1.9807692307692308,\n",
       " 2.1056603773584905,\n",
       " 2.2140221402214024,\n",
       " 1.3333333333333333,\n",
       " 2.957345971563981,\n",
       " 1.2352941176470589,\n",
       " 1.4264150943396225,\n",
       " 2.0,\n",
       " 1.356164383561644,\n",
       " 1.4126984126984128,\n",
       " 1.9930795847750864,\n",
       " 1.2845070422535212,\n",
       " 1.2666666666666666,\n",
       " 2.0,\n",
       " 1.337837837837838,\n",
       " 1.496437054631829,\n",
       " 1.9411764705882353,\n",
       " 1.2738461538461539,\n",
       " 1.22,\n",
       " 1.1897233201581028,\n",
       " 1.2650602409638554,\n",
       " 1.6031746031746033,\n",
       " 1.5180722891566265,\n",
       " 0.8852459016393442,\n",
       " 1.2911392405063291,\n",
       " 2.076923076923077,\n",
       " 1.3333333333333333,\n",
       " 1.0898876404494382,\n",
       " 1.2678571428571428,\n",
       " 1.6527777777777777,\n",
       " 1.2037617554858935,\n",
       " 1.6363636363636365,\n",
       " 1.1728395061728396,\n",
       " 3.6809815950920246,\n",
       " 1.3770491803278688,\n",
       " 1.352112676056338,\n",
       " 1.5550122249388754,\n",
       " 1.7457627118644068,\n",
       " 1.160919540229885,\n",
       " 3.102439024390244,\n",
       " 1.4602409638554217,\n",
       " 1.8148148148148149,\n",
       " 1.329268292682927,\n",
       " 1.3629976580796253,\n",
       " 1.4833948339483394,\n",
       " 1.1762376237623762,\n",
       " 1.6595744680851063,\n",
       " 1.3026315789473684,\n",
       " 1.7002724795640327,\n",
       " 1.44874715261959,\n",
       " 1.4963325183374083,\n",
       " 1.1395348837209303,\n",
       " 1.5384615384615385,\n",
       " 1.6779661016949152,\n",
       " 1.387012987012987,\n",
       " 1.125,\n",
       " 1.2602739726027397,\n",
       " 1.5714285714285714,\n",
       " 1.4679334916864608,\n",
       " 1.5719557195571956,\n",
       " 1.176079734219269,\n",
       " 1.1090573012939002,\n",
       " 1.2727272727272727,\n",
       " 1.2727272727272727,\n",
       " 1.511002444987775,\n",
       " 1.4772727272727273,\n",
       " 1.2829373650107991,\n",
       " 1.126153846153846,\n",
       " 1.6504297994269341,\n",
       " 1.7924528301886793,\n",
       " 2.348936170212766,\n",
       " 1.1923076923076923,\n",
       " 1.7746478873239437,\n",
       " 1.344578313253012,\n",
       " 1.2348284960422165,\n",
       " 2.187725631768953,\n",
       " 1.2727272727272727,\n",
       " 2.331983805668016,\n",
       " 1.2126315789473685,\n",
       " 1.3349633251833741,\n",
       " 1.1174785100286533,\n",
       " 1.4366197183098592,\n",
       " 2.33976833976834,\n",
       " 2.0,\n",
       " 1.526448362720403,\n",
       " 1.32541567695962,\n",
       " 2.1962264150943396,\n",
       " 1.2598752598752598,\n",
       " 1.9184952978056427,\n",
       " 1.7758620689655173,\n",
       " 1.7761732851985559,\n",
       " 1.1853281853281854,\n",
       " 1.0402802101576183,\n",
       " 1.421875,\n",
       " 1.8126888217522659,\n",
       " 1.8957654723127035,\n",
       " 1.3289473684210527,\n",
       " 2.0,\n",
       " 1.345646437994723,\n",
       " 1.667574931880109,\n",
       " 1.5831134564643798,\n",
       " 2.466403162055336,\n",
       " 1.225,\n",
       " 1.7818181818181817,\n",
       " 1.6793002915451896,\n",
       " 1.2610169491525425,\n",
       " 1.1931166347992352,\n",
       " 1.1975308641975309,\n",
       " 1.553191489361702,\n",
       " 1.5039577836411608,\n",
       " 1.3392857142857142,\n",
       " 1.4264705882352942,\n",
       " 1.2185686653771761,\n",
       " 1.6182572614107884,\n",
       " 1.4754098360655739,\n",
       " 1.9170124481327802,\n",
       " 1.163265306122449,\n",
       " 1.6071428571428572,\n",
       " 1.5625,\n",
       " 1.482185273159145,\n",
       " 1.6147757255936674,\n",
       " 1.1071428571428572,\n",
       " 1.5584415584415585,\n",
       " 1.4624145785876994,\n",
       " 1.4366197183098592,\n",
       " 1.5521235521235521,\n",
       " 1.758957654723127,\n",
       " 1.3606911447084233,\n",
       " 1.4583333333333333,\n",
       " 4.013245033112582,\n",
       " 1.7270029673590503,\n",
       " 1.2857142857142858,\n",
       " 3.304812834224599,\n",
       " 1.353191489361702,\n",
       " 1.6129032258064515,\n",
       " 1.1566265060240963,\n",
       " 1.0659025787965617,\n",
       " 1.457070707070707,\n",
       " 1.2317073170731707,\n",
       " 1.9753846153846153,\n",
       " 1.2932862190812722,\n",
       " 1.3654266958424508,\n",
       " 0.7538461538461538,\n",
       " 1.148936170212766,\n",
       " 1.3055555555555556,\n",
       " 1.5606060606060606,\n",
       " 1.36986301369863,\n",
       " 2.1444043321299637,\n",
       " 1.9361022364217253,\n",
       " 1.6,\n",
       " 1.2875,\n",
       " 2.132890365448505,\n",
       " 1.2560975609756098,\n",
       " 1.8333333333333333,\n",
       " 2.466403162055336,\n",
       " 1.2,\n",
       " 2.1227436823104693,\n",
       " 1.2127659574468086,\n",
       " 2.074576271186441,\n",
       " 1.6031746031746033,\n",
       " 1.5548172757475083,\n",
       " 1.4310344827586208,\n",
       " 1.546875,\n",
       " 1.974921630094044,\n",
       " 1.3876221498371335,\n",
       " 1.0196078431372548,\n",
       " 2.5849802371541504,\n",
       " 2.0,\n",
       " 1.3243243243243243,\n",
       " 2.247104247104247,\n",
       " 1.408450704225352,\n",
       " 2.0,\n",
       " 1.749271137026239,\n",
       " 1.7115384615384615,\n",
       " 1.8717201166180757,\n",
       " 1.1730769230769231,\n",
       " 1.2432432432432432,\n",
       " 1.3287671232876712,\n",
       " 1.1046931407942238,\n",
       " 0.859375,\n",
       " 1.4332552693208431,\n",
       " 2.05111821086262,\n",
       " 1.7433962264150944,\n",
       " 1.1904761904761905,\n",
       " 1.2619047619047619,\n",
       " 1.2184615384615385,\n",
       " 1.407942238267148,\n",
       " 1.0666666666666667,\n",
       " 1.6612903225806452,\n",
       " 1.2857142857142858,\n",
       " 2.3247232472324724,\n",
       " 3.1122994652406417,\n",
       " 1.463768115942029,\n",
       " 1.2247191011235956,\n",
       " 1.2093933463796478,\n",
       " 1.5060728744939271,\n",
       " 1.4264150943396225,\n",
       " 1.2710706150341686,\n",
       " 1.830188679245283,\n",
       " 1.6160458452722064,\n",
       " 1.9019607843137254,\n",
       " 2.9246231155778895,\n",
       " 1.2598752598752598,\n",
       " 1.8977635782747604,\n",
       " 1.1219512195121952,\n",
       " 1.25,\n",
       " 0.851963746223565,\n",
       " 1.6774193548387097,\n",
       " 1.2474012474012475,\n",
       " 1.5483870967741935,\n",
       " 1.4047619047619047,\n",
       " 1.0147058823529411,\n",
       " 1.3856812933025404,\n",
       " 1.2206303724928367,\n",
       " 1.46,\n",
       " 2.135593220338983,\n",
       " 1.0434782608695652,\n",
       " 1.5116279069767442,\n",
       " 1.2763157894736843,\n",
       " 1.2899543378995433,\n",
       " 1.7818181818181817,\n",
       " 1.971731448763251,\n",
       " 1.2653061224489797,\n",
       " 1.2702702702702702,\n",
       " 1.8996138996138996,\n",
       " 1.643076923076923,\n",
       " 2.0930232558139537,\n",
       " 3.242424242424242,\n",
       " 1.158699808795411,\n",
       " 1.3472222222222223,\n",
       " 2.0730897009966776,\n",
       " 1.6440677966101696,\n",
       " 2.843601895734597,\n",
       " 1.0,\n",
       " 2.176271186440678,\n",
       " 1.6677316293929711,\n",
       " 1.0415647921760391,\n",
       " 1.9169329073482428,\n",
       " 1.894736842105263,\n",
       " 1.2610169491525425,\n",
       " 2.0434782608695654,\n",
       " 1.993485342019544,\n",
       " 1.419718309859155,\n",
       " 2.0930232558139537,\n",
       " 1.2386363636363635,\n",
       " 1.8596491228070176,\n",
       " 1.0729166666666667,\n",
       " 1.183752417794971,\n",
       " 2.5991902834008096,\n",
       " 2.0338983050847457,\n",
       " 1.2982456140350878,\n",
       " 1.4754098360655739,\n",
       " 1.3026315789473684,\n",
       " 1.5348837209302326,\n",
       " 1.391304347826087,\n",
       " 1.2585470085470085,\n",
       " 2.07773851590106,\n",
       " 1.8244514106583072,\n",
       " 2.3902439024390243,\n",
       " 1.25,\n",
       " 1.1875,\n",
       " 1.364620938628159,\n",
       " 1.0714285714285714,\n",
       " 1.34185303514377,\n",
       " 2.0588235294117645,\n",
       " 2.0521172638436482,\n",
       " 0.9971830985915493,\n",
       " 1.4246575342465753,\n",
       " 1.6431535269709543,\n",
       " 1.7179487179487178,\n",
       " 1.5166666666666666,\n",
       " 1.6885245901639345,\n",
       " 1.510688836104513,\n",
       " 1.2311015118790496,\n",
       " 1.0326086956521738,\n",
       " 1.6615384615384616,\n",
       " 1.5155709342560553,\n",
       " 1.3522975929978118,\n",
       " 1.532258064516129,\n",
       " 1.3522975929978118,\n",
       " 4.055172413793104,\n",
       " 1.2848232848232848,\n",
       " 1.9335548172757475,\n",
       " 1.9184952978056427,\n",
       " 1.5060728744939271,\n",
       " 1.5918367346938775,\n",
       " 1.48,\n",
       " 1.2126315789473685,\n",
       " 1.4411764705882353,\n",
       " 1.345291479820628,\n",
       " 1.1769722814498933,\n",
       " 1.8126888217522659,\n",
       " 1.5625,\n",
       " 2.2222222222222223,\n",
       " 1.4961038961038962,\n",
       " 1.1851851851851851,\n",
       " 1.5584415584415585,\n",
       " 1.3752808988764045,\n",
       " 1.4047619047619047,\n",
       " 1.5498154981549817,\n",
       " 1.6451612903225807,\n",
       " 1.3733333333333333,\n",
       " 1.9285714285714286,\n",
       " 1.5265017667844523,\n",
       " 1.5932203389830508,\n",
       " 1.511111111111111,\n",
       " 1.2702702702702702,\n",
       " 0.9592476489028213,\n",
       " 1.8056426332288402,\n",
       " 2.07942238267148,\n",
       " 1.2452830188679245,\n",
       " 1.2995495495495495,\n",
       " 1.4584615384615385,\n",
       " 2.1413427561837457,\n",
       " 1.8711864406779661,\n",
       " 1.2958963282937366,\n",
       " 2.690582959641256,\n",
       " 1.0898876404494382,\n",
       " 1.3,\n",
       " 1.8571428571428572,\n",
       " 1.3730407523510972,\n",
       " 1.037037037037037,\n",
       " 1.8851963746223566,\n",
       " 1.7017543859649122,\n",
       " 1.8448753462603877,\n",
       " 1.5603217158176943,\n",
       " 1.5603217158176943,\n",
       " 1.9423076923076923,\n",
       " 2.135593220338983,\n",
       " 1.3012048192771084,\n",
       " 1.5265017667844523,\n",
       " 2.227272727272727,\n",
       " 1.4558823529411764,\n",
       " 1.9384615384615385,\n",
       " 1.2084942084942085,\n",
       " 1.0888888888888888,\n",
       " 2.574898785425101,\n",
       " 1.9711191335740073,\n",
       " 1.125,\n",
       " 2.340248962655602,\n",
       " 1.489795918367347,\n",
       " 1.9214501510574018,\n",
       " 1.1748971193415638,\n",
       " 1.1211072664359862,\n",
       " 1.9169329073482428,\n",
       " 1.8566037735849057,\n",
       " 1.2625,\n",
       " 1.0963455149501662,\n",
       " 1.391304347826087,\n",
       " 1.2126315789473685,\n",
       " 1.532258064516129,\n",
       " 1.4462540716612378,\n",
       " 0.8286445012787724,\n",
       " 1.5256723716381417,\n",
       " 1.5070422535211268,\n",
       " 1.4777448071216617,\n",
       " 1.2115384615384615,\n",
       " 1.4225352112676057,\n",
       " 1.9803921568627452,\n",
       " 1.5325301204819277,\n",
       " 1.1304347826086956,\n",
       " 1.5356200527704484,\n",
       " 1.825,\n",
       " 1.8996865203761755,\n",
       " 1.4466403162055337,\n",
       " 1.4688221709006928,\n",
       " 1.4816625916870416,\n",
       " 1.1898734177215189,\n",
       " 1.5263157894736843,\n",
       " 1.4133949191685913,\n",
       " 1.8305084745762712,\n",
       " 1.2876712328767124,\n",
       " 1.7945619335347431,\n",
       " 1.4703557312252964,\n",
       " 1.9534883720930232,\n",
       " 1.3539192399049882,\n",
       " 1.321256038647343,\n",
       " 1.4109589041095891,\n",
       " 1.1185770750988142,\n",
       " 1.5831134564643798,\n",
       " 1.3076923076923077,\n",
       " 1.667621776504298,\n",
       " 3.1088082901554404,\n",
       " 1.8248847926267282,\n",
       " 1.3353115727002967,\n",
       " 1.219712525667351,\n",
       " 1.8545454545454545,\n",
       " 1.3424657534246576,\n",
       " 1.0926517571884984,\n",
       " 1.0961538461538463,\n",
       " 1.5804878048780489,\n",
       " 1.3333333333333333,\n",
       " 1.8210862619808306,\n",
       " 2.094915254237288,\n",
       " 1.1944444444444444,\n",
       " 2.066666666666667,\n",
       " 2.1201413427561837,\n",
       " 1.5918367346938775,\n",
       " 1.4077448747152619,\n",
       " 1.3062730627306274,\n",
       " 1.2098092643051772,\n",
       " 2.1476014760147604,\n",
       " 1.8056426332288402,\n",
       " 1.1170212765957446,\n",
       " 2.282608695652174,\n",
       " 3.1470588235294117,\n",
       " 1.09375,\n",
       " 2.42914979757085,\n",
       " 1.0,\n",
       " 1.7272727272727273,\n",
       " 1.476038338658147,\n",
       " 1.299781181619256,\n",
       " 1.3275862068965518,\n",
       " 1.7962962962962963,\n",
       " 1.1872427983539096,\n",
       " 2.0830188679245283,\n",
       " 1.9933554817275747,\n",
       " 1.24,\n",
       " 1.5106382978723405,\n",
       " 1.078616352201258,\n",
       " 0.900804289544236,\n",
       " 1.5037220843672456,\n",
       " 1.6605166051660516,\n",
       " 1.8516320474777448,\n",
       " 1.286652078774617,\n",
       " 1.4551495016611296,\n",
       " 1.1521739130434783,\n",
       " 1.6348773841961852,\n",
       " 3.644171779141104,\n",
       " 1.3421052631578947,\n",
       " 1.349537037037037,\n",
       " 1.4153846153846155,\n",
       " 1.4,\n",
       " 1.4884910485933505,\n",
       " 1.279317697228145,\n",
       " 1.6600790513833992,\n",
       " 1.4493506493506494,\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aspect(x):\n",
    "    a,b = PIL.Image.open(x).size\n",
    "    return a/b\n",
    "    \n",
    "def ds_mean_aspect(ds):\n",
    "    return [aspect(x) for x,_ in ds]\n",
    "    return np.mean([aspect(x) for x,_ in ds]).item()\n",
    "\n",
    "ds_mean_aspect(cedar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70424d4c-1863-484d-9fff-803c159bf68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27bfb47-d6a2-4e2c-bb7e-a4431713eee5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mds\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "ds = sigcomp2009()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f8a91c1-843a-41e6-a92a-5736f26d7971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 899)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIL.Image.open(ds_train[0][0]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "205de7af-3bd8-4543-8c1d-793a0bf84fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sorted([int(x.split('-')[1]) for x in group_by_y(sigcomp2009()).keys()])\n",
    "\n",
    "s[:int(len(s)*0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "328696ae-73f7-434f-a2f2-ad0be4555b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = cedar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93109516-bbc6-4abb-96df-a304e65093a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_by_y(sigcomp2009(train=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2f5a13-3b4e-4883-a4d6-9cdae528194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_by_y(sigcomp2009()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "818af623-5817-47a8-b0c4-cd0fdacacb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_by_y(cedar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cff0046e-e29b-4ec3-91ba-58ca59c3990e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(940, 60)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = sigcomp2009(train=True)\n",
    "ds_valid = sigcomp2009(train=False)\n",
    "len(ds_train), len(ds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7515c25-732c-4eea-980f-ca9f089bc037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def binarize_image(np_img):\n",
    "    _, otsu_gauss= cv2.threshold(cv2.GaussianBlur(np_img,(5,5),0),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return otsu_gauss\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    torchvision.transforms.Lambda(PIL.Image.open),\n",
    "    torchvision.transforms.Lambda(np.asarray),\n",
    "    torchvision.transforms.Lambda(binarize_image),\n",
    "    torchvision.transforms.Lambda(torch.from_numpy),\n",
    "    torchvision.transforms.Lambda(lambda t : t.unsqueeze(0)),\n",
    "    torchvision.transforms.Resize((122,244)),\n",
    "    v2.RGB(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    torchvision.transforms.Lambda(lambda v : 1.0-(v > 0.88).float()),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "pds_train = PairDataset(ds_train,x_transform=transform)\n",
    "pds_valid = PairDataset(ds_valid,x_transform=transform)\n",
    "x=pds_train[1]\n",
    "show_pair(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e331558e-3e24-482b-8ccc-5058fbf29075",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(pds_train, batch_size=32, shuffle=True, num_workers=0)\n",
    "dl_valid = torch.utils.data.DataLoader(pds_valid, batch_size=64, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d03cd6-a288-480a-9259-7b666f2fdb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=next(iter(dataloader))\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cbc498d-8fa6-4f8d-92d7-b4cdf209a5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 122, 244])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a5c27fa2-a86c-438d-88db-9ef5f9fa1bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 122, 244])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0148a7ce-55ef-464f-a235-688741e714f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False,  True, False, False, False,  True,  True, False,\n",
       "        False,  True, False,  True,  True, False,  True, False,  True,  True,\n",
       "         True,  True, False,  True,  True,  True, False,  True, False, False,\n",
       "        False, False])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b96ffa-e768-4aa0-9fab-1a8f9b639369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5029d6cf-6fb3-4c12-a19b-54ec99001494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 530, 1713])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "x=torchvision.io.read_image(ds[0][0])\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23142d9d-1791-490e-88f0-7e6246639d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3eb2988c-8395-4487-bbbc-2779f408471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13015765-769b-4a0a-97de-c719fb24ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/ml/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class ModifiedResNet18(torch.nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ModifiedResNet18, self).__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        self.cls = torch.nn.Linear(512,1)\n",
    "        \n",
    "        self.features = torch.nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4,\n",
    "            resnet.avgpool,\n",
    "            torch.nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x1,x2):\n",
    "        f1 = self.features(x1)\n",
    "        f2 = self.features(x2)\n",
    "        return self.cls(f1-f2)\n",
    "\n",
    "# Instantiate and test the modified model\n",
    "model = ModifiedResNet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "59de04c1-21df-4b0e-aecb-56a043537467",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedResNet18(torch.nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ModifiedResNet18, self).__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.features = torch.nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4,\n",
    "            torch.nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate and test the modified model\n",
    "model = ModifiedResNet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1cdfb481-3638-4073-a985-7bd2bbd606c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 122, 244])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9a6209ee-f93d-4431-964e-8b54aed23e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16384])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=model(l[0])\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e1c1bdfa-33d1-49a9-bfac-ada9286302db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(x1, x2, label, margin: float = 1.0):\n",
    "    \"\"\"\n",
    "    Computes Contrastive Loss\n",
    "    \"\"\"\n",
    "\n",
    "    dist = torch.nn.functional.pairwise_distance(x1, x2)\n",
    "\n",
    "    loss = (1 - label) * torch.pow(dist, 2) \\\n",
    "        + (label) * torch.pow(torch.clamp(margin - dist, min=0.0), 2)\n",
    "    loss = torch.mean(loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "703076b5-dd0d-4ad1-ab68-59a0a5ced19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 5963.9701\n",
      "Epoch [2/10], Loss: 61.1938\n",
      "Epoch [3/10], Loss: 22.3301\n",
      "Epoch [4/10], Loss: 12.4925\n",
      "Epoch [5/10], Loss: 8.2985\n",
      "Epoch [6/10], Loss: 5.1769\n",
      "Epoch [7/10], Loss: 4.0320\n",
      "Epoch [8/10], Loss: 2.8877\n",
      "Epoch [9/10], Loss: 2.5416\n",
      "Epoch [10/10], Loss: 2.1810\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming model, siamese_dataloader, device, and num_epochs are predefined\n",
    "#model = SiameseNetwork().to(device)  # Your Siamese network model\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        tensor1, tensor2, labels = batch\n",
    "        #tensor1, tensor2, labels = tensor1.to(device), tensor2.to(device), labels.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits1 = model(tensor1)\n",
    "        logits2 = model(tensor2)  # Assumes model returns logits for the match/mismatch prediction\n",
    "        labels = labels.view(-1, 1).float()\n",
    "        loss = criterion(logits1, logits2, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for reporting\n",
    "        running_loss += loss.item() * tensor1.size(0)\n",
    "\n",
    "    # Calculate and print the average loss per epoch\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac15ea3-621f-4529-b105-983d16a7f913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f03cd65-9a82-489b-970b-3d2240c19b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd850841-8354-4098-8050-51173d8ccafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1084158a-6882-43f8-8c29-b07f57c9540c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Training Loss: 0.7590\n",
      "Epoch [1/5], Validation Loss: 0.6971, Accuracy: 50.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, labels)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Accumulate loss for reporting\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Assuming model, siamese_dataloader, device, and num_epochs are predefined\n",
    "#model = SiameseNetwork().to(device)  # Your Siamese network model\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Optimizer\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in dl_train:\n",
    "        tensor1, tensor2, labels = batch\n",
    "        # tensor1, tensor2, labels = tensor1.to(device), tensor2.to(device), labels.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(tensor1, tensor2)  # Assumes model returns logits for the match/mismatch prediction\n",
    "        labels = labels.view(-1, 1).float()\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for reporting\n",
    "        running_loss += loss.item() * tensor1.size(0)\n",
    "\n",
    "    # Calculate and print the average loss per epoch\n",
    "    epoch_loss = running_loss / len(dl_train.dataset)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Evaluation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dl_valid:\n",
    "            tensor1, tensor2, labels = batch\n",
    "            # tensor1, tensor2, labels = tensor1.to(device), tensor2.to(device), labels.to(device, dtype=torch.float32)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(tensor1, tensor2)\n",
    "            labels = labels.view(-1, 1).float()\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            # Accumulate validation loss\n",
    "            val_loss += loss.item() * tensor1.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predictions = (logits >= 0.5).float()  # Assuming a binary classification with threshold 0.5\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate and print the average validation loss and accuracy per epoch\n",
    "    avg_val_loss = val_loss / len(dl_valid.dataset)\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a875264-010b-4c58-bf73-69908301a725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f2d5a-153c-4f4e-85dd-cd1530af1411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189f9df-5389-4b74-95b9-8369599e198f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b3de6-8665-4288-9018-1ab16a523c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cd11c02e-c05a-41db-8f9e-d9b177cf2a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.8701\n",
      "Epoch [2/5], Loss: 0.7975\n",
      "Epoch [3/5], Loss: 0.7447\n",
      "Epoch [4/5], Loss: 0.7483\n",
      "Epoch [5/5], Loss: 0.7004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in dl_train:\n",
    "        tensor1, tensor2, labels = batch\n",
    "        #tensor1, tensor2, labels = tensor1.to(device), tensor2.to(device), labels.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(tensor1, tensor2)  # Assumes model returns logits for the match/mismatch prediction\n",
    "        labels = labels.view(-1, 1).float()\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for reporting\n",
    "        running_loss += loss.item() * tensor1.size(0)\n",
    "\n",
    "    # Calculate and print the average loss per epoch\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611184c1-d73a-4650-a406-aaf700ba2716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f7ab2bd-ed69-4fe4-96f8-eb6b8026b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.X = torch.nn.Linear(10,10)\n",
    "        #self.Y = torch.nn.Sequential(self.X, self.X)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.X(x)\n",
    "        return x\n",
    "a=A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "476a06ee-a89c-4be6-98cf-04752241a05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0558,  0.2953,  0.1002,  0.2784, -0.0073,  0.2083, -0.2233, -0.0471,\n",
       "          -0.0122, -0.0924],\n",
       "         [-0.2368, -0.0949, -0.2500,  0.0622,  0.1938, -0.2045,  0.1575, -0.0427,\n",
       "           0.0704, -0.0253],\n",
       "         [-0.1448, -0.1601,  0.0317,  0.0894,  0.2613,  0.1927,  0.2317,  0.0275,\n",
       "           0.0240,  0.2598],\n",
       "         [ 0.1159,  0.1685,  0.2193,  0.2538, -0.3033, -0.3081, -0.2351, -0.3030,\n",
       "           0.0064,  0.1555],\n",
       "         [-0.3146,  0.0103,  0.3017, -0.1348, -0.2574,  0.2274, -0.0882, -0.1330,\n",
       "           0.1932,  0.1611],\n",
       "         [-0.0068,  0.2526,  0.1385, -0.1186, -0.1716, -0.1101, -0.0375, -0.0768,\n",
       "          -0.2334,  0.0668],\n",
       "         [ 0.1988,  0.1349, -0.2593, -0.0792,  0.1719, -0.1907, -0.2225, -0.2958,\n",
       "           0.2216, -0.1340],\n",
       "         [-0.1870, -0.1073,  0.1612,  0.0643, -0.0088, -0.2451, -0.1487,  0.2127,\n",
       "           0.1145,  0.1859],\n",
       "         [-0.3031,  0.3154, -0.2972,  0.0531, -0.0348,  0.0178, -0.2408,  0.1282,\n",
       "           0.2695, -0.0353],\n",
       "         [-0.0502,  0.0050, -0.2604,  0.1966,  0.2913,  0.2831, -0.1644,  0.3065,\n",
       "          -0.1531,  0.0732]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2754, -0.1150, -0.2428,  0.2022, -0.2800, -0.1553,  0.0553, -0.0976,\n",
       "          0.2147,  0.1062], requires_grad=True)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "814e6e66-8521-4d6e-aded-5e7d0d5d2c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4295, -0.2247,  0.3050, -0.1789, -0.3813, -0.5375, -0.0674, -0.1636,\n",
       "          0.1320,  0.6198]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(torch.rand(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a10c2c52-bcda-4719-b822-59b0b5e69ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Generate some example data\n",
    "embeddings = np.random.rand(60000, 128).astype('float32')  # 1000 items, 128-dimensional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "980d990d-9433-4013-8687-a79ef8a3cfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bd5c0a8-1d33-4914-b1f6-0cf2db8bbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `IndexIVFFlat`\n",
    "dimension = embeddings.shape[1]\n",
    "nlist = 200  # number of clusters, set according to dataset size (e.g., sqrt(n) is a common choice)\n",
    "quantizer = faiss.IndexFlatL2(dimension)  # the base quantizer\n",
    "index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b66001f8-3d58-450c-a9d8-3fb3fde537e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the index on a sample of data\n",
    "index.train(embeddings)  # required before adding vectors to an IVFFlat index\n",
    "index.add(embeddings)    # add embeddings to the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ec73ccd-8aa6-41f3-b22c-12cbfa670f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of Neighbors: [[ 9808 47029 47531 37302  9020]]\n",
      "Distances to Neighbors: [[12.514496 14.070881 14.425043 14.658357 14.849606]]\n"
     ]
    }
   ],
   "source": [
    "# Query the index\n",
    "query_vector = np.random.rand(128).astype('float32')  # 128-dimensional query vector\n",
    "k = 5  # number of nearest neighbors\n",
    "index.nprobe = 10  # number of clusters to search, trade-off between speed and accuracy\n",
    "\n",
    "# Search for k nearest neighbors\n",
    "distances, indices = index.search(np.array([query_vector]), k)\n",
    "\n",
    "# Print results\n",
    "print(\"Indices of Neighbors:\", indices)\n",
    "print(\"Distances to Neighbors:\", distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634d33c-d56a-42da-b989-82c6c6b71244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f180916-09f9-406b-94a6-4c6bc72300cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
